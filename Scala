pyspark
from pyspark.ml.fpm import FPGrowth

dataFrame = spark.read.csv("s3://dotley-spark-bucket/Bakery.csv", header=True).rdd

keyValuePairs = dataFrame.map (lambda row : (row['TransactionNo'], {row['Items']}))
collectedKeyValuePairs = keyValuePairs.reduceByKey( lambda a,b : a.union(b) )

itemsToList=collectedKeyValuePairs.map(lambda x : (x[0], list(x[1])))
transactionsFrame=spark.createDataFrame(itemsToList, ["id","items"])

model = FPGrowth(itemsCol="items", minSupport=0.03, minConfidence=0.6)
modelResults = model.fit(transactionsFrame)

modelResults.associationRules.show()

modelResults.freqItemsets.show()
